---
title: "TS_FinalProject_Ferraro_Norelli_YU"
author: "Ricco, Nicole & Nick"
date: '2022-03-26'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#### Data Read in & Wrangling

```{r}
#libraries
library(tswge)
library(dplyr)
library(tidyverse)
library(readxl)
# Set this to data folder for your file
setwd("/Users/riccoferraro/Documents/SMU/TimeSeries/TimeSeriesFinalProject/data")

# Read in DFWA electricity Data
dfwa.electricity = read.csv("AVG_ELEC_DFWA_TX.csv",col.names = c("DATE", "AVG_EP"), 
                          colClasses = c(DATE="character", AVG_EP="character"))

# Read in CPI data for Southern Urban area
cpi = read_excel("SouthernUrbanCPI.xlsx",sheet = "BLS Data Series", skip = 11)
# Getting rid of Half1 and Half2 which starts with S
cpi = cpi %>% filter(!grepl('S',Period) )
# Getting rid of Annual which labeled as M13
cpi = cpi %>% filter(!grepl('M13',Period) )

# Read in Gas Price data from same area
gas.price = read.csv("Dallas_FWA_GAS.csv")

# Read in Temperature Data & cleaning
temp = read_excel("DallasAreaTemp.xlsx", sheet = "Sheet1")
temp = temp %>% tidyr::pivot_longer(
  cols = starts_with("Mon_"),
  names_to = "Month",
  values_to = "Temperature"
)
temp = temp[1:386,]

# subset dataset
# which(dfwa.electricity$DATE=="1990-01-01") # 135
dfwa.electricity = dfwa.electricity[135:520,]
rownames(dfwa.electricity) <- 1:nrow(dfwa.electricity)
dfwa.electricity

# which(cpi$Year==1990 & cpi$Period=="M01")
cpi = cpi[91:476,]
rownames(cpi) <- 1:nrow(cpi)

# which(gas.price$DATE=="1990-01-01") # 145
gas.price = gas.price[145:530,]
rownames(gas.price) <- 1:nrow(gas.price)


#### Creating ultimate data frame under variable 'df' ####
df = dfwa.electricity
df$CPI = cpi$Value
df$GAS_P = gas.price$APUS37A7471A
df$AVG_EP = as.numeric(df$AVG_EP)
df$TEMP = temp$Temperature

#### Due to distribution market deregulation in 1995, team decided to cut the realization
#### prior to 2000
# which(df$DATE=="2000-01-01") # 121
df = df[121:386,]
rownames(df) <- 1:nrow(df)

plotts.wge(df$AVG_EP)
plotts.wge(df$CPI)
plotts.wge(df$GAS_P)
plotts.wge(df$TEMP)
```

#### EDA and Univariate Modeling
- Short term forecast horizon is determined to be 3 month since it might be helpful for short term enerage usage planning
- Long term forecast horizen is determined to be 36 month, since it is helpful to forecast pricing few years out for infrastructure and budget planning
```{r}
# There seem to be a slowly damping behavior which might support difference the data
plotts.sample.wge(df$AVG_EP)

# Try overfitting
est = est.ar.wge(df$AVG_EP, p=16, type='burg')
# compare this to seasonality of 12 
factor.wge(phi = c(rep(0,11),1))

# By using overfitting method, 1-B term seems to have the largest absolute reciprocal root which by itself supports differencing the data
# Additionally, there seem to have a 1-B^12 seasonality, even some of the factors such as 1+B at system frequency of -.5 and 1+1.73B+1B^2 at System frequency of 0.4167 are not as close to the unit circle. Although it might worth exploring s = 12 also

d1 = artrans.wge(df$AVG_EP, phi.tr = 1)
# with the differenced data there seem to have some sort of seasonal behavior at 12 left
d1.12 = artrans.wge(d1, phi.tr = c(rep(0,11),0.4))
dev.off()
acf(d1.12) # AIC looks about white noise
ljung.wge(d1.12, K=24) # K=24 reject white noise hypothesis
ljung.wge(d1.12, K=48) # K = 48 reject white noise 
# Thus models require further modeling

# est1.12 = aic5.wge(d1.12, p=0:15, q=0:5) # AIC picked p = 7, q=4
# est.1.12.bic = aic5.wge(d1.12, p=0:15, q=0:5, type = 'bic') # bic picked p=0, q=0
# est.1.12.aicc = aic5.wge(d1.12, p=0:15, q=0:5, type = 'aicc') # aicc picked p=1, q=0
# seems AIC leaning towards a fancy model, while bic leaning towards white noise.
# I will attempt something in the middle by using AR(1) instead
params.est = est.arma.wge(d1.12, p=1)
acf(params.est$res) # residuals looks about white noise
ljung.wge(params.est$res, K=24) # K=24 reject white noise hypothesis
ljung.wge(params.est$res, K=48) # K = 48reject null hypothesis of white noise

# Try fancier model identified by AIC
params.est = est.arma.wge(d1.12, p=7,q=4)
acf(params.est$res) # residuals looks about white noise
ljung.wge(params.est$res, K=24) # K=24 fail to reject white noise hypothesis
ljung.wge(params.est$res, K=48) # K = 48 fail to reject null hypothesis of white noise

# All models are wrong some are useful - we will proceed with fancier model for now
model1.param = mult.wge(fac1 = params.est$phi, fac2 = c(rep(0,11),0.4))
pred.short = fore.arima.wge(df$AVG_EP, phi = model1.param$model.coef, theta = params.est$theta,
                            d = 1, n.ahead = 3, limits = T, lastn = T)
ASE.short = mean((df$AVG_EP[264:266]-pred.short$f)^2)
ASE.short # 3.184093e-05 -> 0.0000318  #New 5.988891e-05 -> 0.0000599

pred.long = fore.arima.wge(df$AVG_EP, phi = model1.param$model.coef, theta = params.est$theta,
                            d = 1, n.ahead = 36, limits = T, lastn = T)
ASE.long = mean((df$AVG_EP[(266-36+1):266]-pred.long$f)^2)
ASE.long # 0.0001725023

# rolling.res.short = roll.win.rmse.wge(df$AVG_EP,phi = model1.param$model.coef, theta = params.est$theta, d = 1, horizon = 3 )
# rolling.res.short # RMSE = 0.004, ASE = 1.6e-0.5 -> 0.000016, nums of windows = 239

# rolling.res.long = roll.win.rmse.wge(df$AVG_EP,phi = model1.param$model.coef, theta = params.est$theta, d = 1, horizon = 36)
# rolling.res.long # RMSE = 0.014, ASE= 0.000196, num of windows = 206

```

#### Try signal plus noise model
```{r}
x = df$AVG_EP
n = length(x)
t = 1:n
d = lm(x~t)
# x.z are the residuals from the regression line
x.z = x-d$coefficients[1] - d$coefficients[2]*t
plotts.sample.wge(x.z)

ar.z = aic.wge(x.z, p=0:15)
x.trans = artrans.wge(x, phi.tr = ar.z$phi)
t.trans = artrans.wge(t, phi.tr = ar.z$phi)
fit = lm(x.trans~ t.trans)
summary(fit)
# As can be seen, after account for the serial correlation (AR(14)), there is strong evidence to suggest that the slope is significantly different from zero (pvalue < 0.0001). So we will take the trend out and proceed

# try bootstrapping method just to be sure
wbg.boot.wge(x, sn=103)
# Bootstrap-based test for trend failed to reject with p-value = 0.1078, however we will proceed to try out how using trend helps
ar.est = est.ar.wge(x = x.z, p=14, type = 'burg')
dev.off()
acf(ar.est$res)
ljung.wge(ar.est$res)
ljung.wge(ar.est$res, K=48)
# both tests reject white noise
m2.result = fore.sigplusnoise.wge(x, linear = TRUE, max.p = 15, n.ahead = 3, lastn = TRUE, limits=TRUE)
ASE.short.m2 = mean((df$AVG_EP[264:266]-m2.result$f)^2)
ASE.short.m2 # 6.718437e-05 -> 0.0000672
m2.result.long = fore.sigplusnoise.wge(x, linear = TRUE, max.p = 15, n.ahead = 36, lastn = TRUE, limits=TRUE)
ASE.long.m2 = mean((df$AVG_EP[(266-36+1):266]-m2.result.long$f)^2)
ASE.long.m2 # 0.0001268439

```

#### Visualization
```{r}
library(ggplot2)
df[['DATE']] <- as.Date(df[['DATE']], format='%Y-%m-%d')

# Convert short term prediction to dataframe
pred.short.df = data.frame(Date = df$DATE[264:266], prediction = pred.short$f, upper = pred.short$ul, lower = pred.short$ll)

colors <- c("Actual Price" = "#FC4E07", "Predicted Price" = "#E7B800", "Prediction Limit"= "#E7B800")
ggplot(data = df[260:266,], aes(x=DATE, y=AVG_EP, color="Actual Price"))+
  geom_line( size = 1) +
  ggtitle("Short term average Electricity price forecast")+xlab("Date")+ylab("Average Price") +
  geom_line(data = pred.short.df,aes(x=Date, y=prediction), color="#FC4E07", size=1.1) +
  geom_point(data = pred.short.df,aes(x=Date, y=prediction), color="#FC4E07", size=1.5)+
  geom_line(data = pred.short.df,aes(x=Date, y=upper), color="#E7B800", size=1.1)+
  geom_point(data = pred.short.df,aes(x=Date, y=upper), color="#E7B800", size=1.1)+
  geom_line(data = pred.short.df,aes(x=Date, y=lower), color="#E7B800", size=1.1)+ 
  geom_point(data = pred.short.df,aes(x=Date, y=lower), color="#E7B800", size=1.1)+
  scale_color_manual(values = colors) + theme_classic()

```

#### Trial - Nicole

```{r}
plotts.sample.wge(df$AVG_EP)
# slowly damping autocorrelations
# spectral density peaks at 0 (wandering behavior)
# possible seasonal peak at 1/12 = .0833333 (monthly)
# est.ar.wge(df$AVG_EP,p=15,type="burg")
# factor.wge(phi=c(rep(0,11),1))
# some evidence of s=12 in overfit, though Abs Recip should be a higher

# take difference and look at acf
AVE_EP_d1 = artrans.wge(df$AVG_EP,phi.tr=1)
dev.off()
acf(AVE_EP_d1)
plotts.sample.wge(AVE_EP_d1)
# characteristic seasonal component for 12 months (ACF large at multiples of 12)
AVE_EP_d1_s12 = artrans.wge(AVE_EP_d1,phi.tr=c(rep(0,11),1))
plotts.sample.wge(AVE_EP_d1_s12)
dev.off()
acf(AVE_EP_d1_s12)
# doesn't look like white noise
# aic5.wge(AVE_EP_d1_s12,p=0:15) #13,0 12,2 12,0
EP_est = est.arma.wge(AVE_EP_d1_s12,p=12)

# short 3 month ARUMA(12,1,0) s=12
# roll.win.ase.wge(df$AVG_EP,horizon=3,s=12,d=1,phis=EP_est$phi,thetas=EP_est$theta)
#   2.8495e-05 -> 0.0000285
f.short = fore.arima.wge(df$AVG_EP,phi=EP_est$phi,theta=EP_est$theta,s=12,d=1,n.ahead=3,lastn=TRUE)
ASE.short = mean((df$AVG_EP[264:266]-f.short$f)^2)
ASE.short #3.595854e-05 -> 0.000036

# long 36 month ARUMA(12,1,0) s=12
# roll.win.ase.wge(df$AVG_EP,horizon=36,s=12,d=1,phis=EP_est$phi,thetas=EP_est$theta)
# 0.0004547268
f.long = fore.arima.wge(df$AVG_EP,phi=EP_est$phi,theta=EP_est$theta,s=12,d=1,n.ahead=36,lastn=TRUE)
ASE.long = mean((df$AVG_EP[(266-36+1):266]-f.long$f)^2)
ASE.long 
#0.001223659

# try other AIC5 options with long forecast: ARUMA(13,1,0) s=12 
EP_est_13 = est.arma.wge(AVE_EP_d1_s12,p=13)
# roll.win.ase.wge(df$AVG_EP,horizon=36,s=12,d=1,phis=EP_est_13$phi,thetas=EP_est_13$theta)
#   0.0004697769
f = fore.arima.wge(df$AVG_EP,phi=EP_est_13$phi,theta=EP_est_13$theta,s=12,d=1,n.ahead=36,lastn=TRUE)
mean((df$AVG_EP[(266-36+1):266]-f$f)^2)
#0.001237814

# try 12,2 ARUMA(12,1,2) s=12
EP_est_12_2 = est.arma.wge(AVE_EP_d1_s12,p=12,q=2)
# roll.win.ase.wge(df$AVG_EP,horizon=36,s=12,d=1,phis=EP_est_12_2$phi,thetas=EP_est_12_2$theta)
#  0.0004835913
f = fore.arima.wge(df$AVG_EP,phi=EP_est_12_2$phi,theta=EP_est_12_2$theta,s=12,d=1,n.ahead=36,lastn=TRUE)
mean((df$AVG_EP[(266-36+1):266]-f$f)^2) 
# 0.00128316

# None of these beat Nick's ARUMA(13,1,5) s=12

# Try another model entirely - take 1st diff then fit an ARMA
AVE_EP_d1 = artrans.wge(df$AVG_EP,phi.tr=1)
# aic5.wge(AVE_EP_d1,p=0:15,q=0:5) #15,5
# aic5.wge(AVE_EP_d1,p=10:20,q=0:5) #15,5
# aic5.wge(AVE_EP_d1,p=0:15,q=0:5,type="bic") #12,0 13,1

# ARIMA(15,1,5)
EP_est_15_5 = est.arma.wge(AVE_EP_d1,p=15,q=5)
# short 3 month
# roll.win.ase.wge(df$AVG_EP,horizon=3,d=1,phis=EP_est_15_5$phi,thetas=EP_est_15_5$theta)
#   3.695999e-05
dev.off()
f.short.15.5 = fore.arima.wge(df$AVG_EP,phi=EP_est_15_5$phi,theta=EP_est_15_5$theta,d=1,n.ahead=3,lastn=TRUE)
ASE.short = mean((df$AVG_EP[264:266]-f.short.15.5$f)^2)
ASE.short #4.216765e-05 -> 0.000042167

# 36 month ARIMA(15,1,5)
# roll.win.ase.wge(df$AVG_EP,horizon=36,d=1,phis=EP_est_15_5$phi,thetas=EP_est_15_5$theta)
# 0.0002368869
f.long.15.5 = fore.arima.wge(df$AVG_EP,phi=EP_est_15_5$phi,theta=EP_est_15_5$theta,d=1,n.ahead=36,lastn=TRUE)
ASE.long = mean((df$AVG_EP[(266-36+1):266]-f.long.15.5$f)^2)
ASE.long 
# 0.0001089089

# ARIMA(12,1,0)
EP_est_12_0 = est.arma.wge(AVE_EP_d1,p=12)
# short 3 month
# roll.win.ase.wge(df$AVG_EP,horizon=3,d=1,phis=EP_est_12_0$phi)
#  2.661653e-05
f.short.12.0 = fore.arima.wge(df$AVG_EP,phi=EP_est_12_0$phi,d=1,n.ahead=3,lastn=TRUE)
ASE.short = mean((df$AVG_EP[264:266]-f.short.12.0$f)^2)
ASE.short # 8.029078e-05 -> 0.0000893

# 36 month ARIMA(12,1,0)
# roll.win.ase.wge(df$AVG_EP,horizon=36,d=1,phis=EP_est_12_0$phi)
# 0.0002323361
f.long.12.0 = fore.arima.wge(df$AVG_EP,phi=EP_est_12_0$phi,d=1,n.ahead=36,lastn=TRUE)
ASE.long = mean((df$AVG_EP[(266-36+1):266]-f.long.12.0$f)^2)
ASE.long 
# 0.0001502498


```

#### Trial - Ricco
```{r}
plotts.sample.wge(df$AVG_EP)

## over-fit like our lives depend on it
overfit_ar_30_ricco=est.ar.wge(df$AVG_EP,p=50, type='burg')

# Clearly a 1-B in there. try removing it and over-fitting again. 
AVG_E_i1_ricco = artrans.wge(df$AVG_EP, c(1))
overfit_ar_30_i1_ricco=est.ar.wge(AVG_E_i1_ricco,p=20, type='burg')
# nonstationary_lambda = mult.wge(fac1=c(1-1.7276B+0.9942B^2), c(1+0.9951B), c(1+0.0130B+0.9896B^2), c(1+0.9916B+0.9889B^2))
nonstationary_lambda_ricco = mult.wge(c(1.7276,-0.9942), c(-0.9951), c(-0.0130,-0.9896), c(-0.9916,-0.9889))
nonstationary_lambda$model.coef
AVG_E_lambda_corrected_ricco = artrans.wge(df$AVG_EP, c(nonstationary_lambda$model.coef))
aic_lambda_corrected_ricco = aic.wge(AVG_E_lambda_corrected_ricco, p=0:12, q=0:5, type="bic")
forecast_arma = fore.aruma.wge(df$AVG_EP, phi=aic_lambda_corrected_ricco$phi, theta=aic_lambda_corrected_ricco$theta, d=1, n.ahead = 36,limits = FALSE, plot=TRUE, lastn = TRUE, lambda =c(nonstationary_lambda$model.coef))

forecast_arma_ricco = fore.aruma.wge(df$AVG_EP, phi=overfit_ar_30_i1_ricco$phi,n.ahead = 36,limits = FALSE, plot=TRUE, lastn = TRUE)
## ^^^ YUCK! that looks terrible. let's try a different approach. 

# try finding best long non-stationary estimates Seasonality by rolling window rmse (this has O(n^2) runtime complexity)
best_s_ricco = 0
best_d_ricco = 0
max_s_ricco = 10
max_d_ricco = 2
best_rsme_seasonality_search_and_wandering_search = 10000.0
for (s_try in 0:max_s_ricco) {
  for (d_try in 0:max_d_ricco) {
    rolling.res.long_ricco = roll.win.rmse.wge_ricco(df$AVG_EP, d = d_try, s=s_try, horizon = 36, plot=FALSE)
    if(rolling.res.long_ricco$rwRMSE < best_rsme_seasonality_search_and_wandering_search) {
      best_rsme_seasonality_search_and_wandering_search = rolling.res.long_ricco$rwRMSE
      best_s_ricco = s_try
      best_d_ricco = d_try
    }
  }
}
print(paste("best long rolling window s was:", best_s_ricco))
print(paste("best long rolling window d was:", best_d_ricco))

# best s=0 and d=1 
AVG_E_i1_ricco = artrans.wge(df$AVG_EP, c(1))

# now find best p and q with a rolling window wide grid search
best_p_wide_ricco = 0
best_q_wide_ricco = 0
best_cost_wide_ricco = 10000
best_rsme_s0_d1_p_search_wide = 10000.0
best_last36_ase_wide = 10000.0
q_seq_wide_ricco = seq(1, 11, 5)
p_seq_wide_ricco = seq(1, 31, 10)
for(q_try in q_seq_wide_ricco) {
  for (p_try in p_seq_wide_ricco) {
    was_error = FALSE
    tryCatch(expr = {
      print(paste("trying p: ", p_try, "and q: ", q_try))
      capture.output(est_p_q_search_ricco <- est.arma.wge(AVG_E_i1_ricco, p=p_try, q=q_try), file='NUL')    
      rolling.res.long_ricco = roll.win.rmse.wge_ricco(df$AVG_EP, phi=est_p_q_search_ricco$phi, theta=est_p_q_search_ricco$theta, d=1, s=0,  horizon = 36, plot=FALSE)
      capture.output(f_ricco <- fore.aruma.wge(df$AVG_EP, phi=est_p_q_search_ricco$phi, d=1, s=0, n.ahead=36, lastn=TRUE, plot=FALSE))
      prediction_ase_ricco = mean((df$AVG_EP[(266-35):266]-f$f)^2) 
      # weight last 36 higher because they are the forecasts we should care about most
      cost_ricco = (rolling.res.long_ricco$rwRMSE + prediction_ase_ricco)/2
      if(cost_ricco < best_cost_wide_ricco) {
        best_cost_wide_ricco = cost_ricco
        best_rsme_s0_d1_p_search_wide = rolling.res.long_ricco$rwRMSE
        best_last36_ase_wide = prediction_ase_ricco
        best_p_wide_ricco = p_try
      }
    },
    error = function(e) {
      print(paste("an error occured for p: ", p_try, "and q: ", q_try))
      was_error = TRUE
    })
    if(was_error)
      next
  }
}
print(paste("best long + immediate rolling window p with wide search was:", best_p_wide_ricco))
print(paste("best long + immediate rolling window q with wide search was:", best_q_wide_ricco))

# now find best p and q with a rolling window narrow grid search
best_p_narrow_ricco = 0
best_q_narrow_ricco = 0
best_cost_narrow_ricco = 10000
best_rsme_s0_d1_p_search_narrow = 10000.0
best_last36_ase_narrow = 10000.0
q_seq_narrow_ricco = seq(1, 4, 1)
p_seq_narrow_ricco = seq(25, 31, 1)
for(q_try in q_seq_narrow_ricco) {
  for (p_try in p_seq_narrow_ricco) {
    was_error = FALSE
    tryCatch(expr = {
      print(paste("trying p: ", p_try, "and q: ", q_try))
      capture.output(est_p_q_search_ricco <- est.arma.wge(AVG_E_i1_ricco, p=p_try, q=q_try), file='NUL')    
      rolling.res.long_ricco = roll.win.rmse.wge_ricco(df$AVG_EP, phi=est_p_q_search_ricco$phi, theta=est_p_q_search_ricco$theta, d=1, s=0,  horizon = 36, plot=FALSE)
      capture.output(f_ricco <- fore.aruma.wge(df$AVG_EP, phi=est_p_q_search_ricco$phi, d=1, s=0, n.ahead=36, lastn=TRUE, plot=FALSE))
      prediction_ase_ricco = mean((df$AVG_EP[(266-35):266]-f$f)^2) 
      # weight last 36 higher because they are the forecasts we should care about most
      cost_ricco = (rolling.res.long_ricco$rwRMSE + prediction_ase_ricco)/2
      if(cost_ricco < best_cost_narrow_ricco) {
        best_cost_narrow_ricco = cost_ricco
        best_rsme_s0_d1_p_search_narrow = rolling.res.long_ricco$rwRMSE
        best_last36_ase_narrow = prediction_ase_ricco
        best_p_narrow_ricco = p_try
      }
    },
    error = function(e) {
      print(paste("an error occured for p: ", p_try, "and q: ", q_try))
      was_error = TRUE
    })
    if(was_error)
      next
  }
}
print(paste("best long + immediate rolling window p with narrow search was:", best_p_narrow_ricco))
print(paste("best long + immediate rolling window q with narrow search was:", best_q_narrow_ricco))

best_rsme_s0_d1_p_search_narrow^2
best_last36_ase_narrow


# best P was p=31 q=0, WOW! A huge and complex model BUT it was rolling window RSME verified!
#  I wonder how the ARIMA(31,1,0) would do on future, unseen data. it’s probably just REALLY good at fitting the signal we have, even if we rolling window verify. true cross-validation would be better, if we had the data.
print(paste("best long rolling (36) ase was:", best_rsme_s0_d1_p_search^2, "for p:", best_p_ricco, "for q:", best_q_ricco, "and d = 1"))
f_ricco = fore.aruma.wge(df$AVG_EP, phi=best_phi_estimates, d = 1, s=0, n.ahead=36, lastn=TRUE)
prediction_ase_ricco = mean((df$AVG_EP[(266-35):266]-f$f)^2) 
print(paste("Last 36 ASE was s:", prediction_ase_ricco, "for p:", best_p_ricco, "and d = 1"))

# interestingly the ARIMA(72,1,0) does poorly on the last few samples! maybe a slightly different process? 
#If we look at the plot we can see that there is periodicity in the data until JUST when the forecasts start. I believe it's this periodicity that is messing things up. 

# residuals look VERY white, maybe a slight amount of heteroskeascitity and trend at the very end? 
plotts.sample.wge(f_ricco$resid)

# interestingly, ljung box test cannot reject non-stationarity in the residuals! This seems weird. 
ljung.wge(f_ricco$resid)

```

Appendix:
A Modified version of current roll.win.rmse.wge in github (uses `fore.aruma.wge` from cran, and doesn't print), to use the latest tswge, replace `fore.aruma.wge` with `fore.arima.wge`)
```{r} 
#Rolling Window RMSE Function
# series is the array of the series
# horizon is how far you want to predict into the future
# d is the order of the differencing: (1-B^)^d
# s is the order of the seasonality: (1-B^s)
# phi = coefficients of the stationary AR term
# theta = coefficients of the invertible MA term

# It simply takes the given horizon and the model in the form of s,d,phis and 
# thetas and figures out how many windows it can create in the data (series) and then calculates the ASE for each window.  
#The output is the average off all the ASEs from each individual window.  

roll.win.rmse.wge_ricco = function(series, horizon = 2, s = 0, d = 0, phi = 0, theta = 0, plot=FALSE)
{

  
  #DEFINE fore.arma.wge2
  
  fore.arma.wge2=function(x,phi=0,theta=0,n.ahead=5,lastn=FALSE, plot=FALSE,alpha=.05,limits=TRUE, xbar2 = NULL)
  {
    # lastn=TRUE indicates that the last n data values are to be forecast
    # lastn=FALSE (default) indicates we want foreacts for n values beyond the end of the realization
    n=length(x)
    p=length(phi)
    if(sum(phi^2)==0) {p=0}
    q=length(theta)
    if(sum(theta^2)==0) {q=0}
    #resid=rep(0,n)
    npn.ahead=n+n.ahead
    xhat=rep(0,npn.ahead)
    if(is.null(xbar2))
    {
      xbar=mean(x)
    }
    else
    {
      xbar = xbar2
    }
    
    const=1
    if (p > 0) {for(jp in 1:p) {const=const-phi[jp]}}
    #
    #
    # Calculate Box-Jenkins Forecasts
    #
    #
    #Calculating Residuals
    #
    resid=backcast.wge(x,phi,theta,n.back=50)
    #
    #
    #maconst=const*xbar
    #p1=max(p+1,q+1)
    #for (i in p1:n) {resid[i]=x[i]
    #   if ( p > 0) {for (jp in 1:p) {resid[i]=resid[i]-phi[jp]*x[i-jp]}}
    #   if (q > 0) {for (jq in 1:q) {resid[i]=resid[i]+theta[jq]*resid[i-jq]}}
    #                   resid[i]=resid[i]-maconst}
    #
    # Calculating Forecasts
    #
    #
    npn.ahead=n+n.ahead
    xhat=rep(0,npn.ahead)
    mm=n
    #
    #lastn = TRUE
    #
    if(lastn==TRUE) {mm=n-n.ahead}
    #
    #
    for (i in 1:mm) {xhat[i]=x[i]}
    for (h in 1:n.ahead) {
      if (p > 0) {for (jp in 1:p) {xhat[mm+h]=xhat[mm+h]+phi[jp]*xhat[mm+h-jp]}}
      if ((h<=q)&(h>0)) {for(jq in h:q) {xhat[mm+h]=xhat[mm+h]-theta[jq]*resid[mm+h-jq]}}
      xhat[mm+h]=xhat[mm+h]+xbar*const}
    #
    #
    #   Calculate psi weights for forecasts limits
    #
    #
    xi=psi.weights.wge(phi,theta,lag.max=n.ahead)
    #
    #
    #
    #Setting up for plots
    nap1=n.ahead+1
    fplot=rep(0,nap1)
    maxh=mm+n.ahead
    llplot=rep(0,nap1)
    ulplot=rep(0,nap1)
    f=rep(0,nap1)
    ll=rep(0,nap1)
    ul=rep(0,nap1)
    wnv=0
    xisq=rep(0,n.ahead)
    se=rep(0,n.ahead)
    se0=1
    for (i in 1:n) {wnv=wnv+resid[i]**2}
    wnv=wnv/n
    xisq[1]=1
    for (i in 2:n.ahead) {xisq[i]=xisq[i-1]+xi[i-1]^2}
    for (i in 1:n.ahead) {se[i]=sqrt(wnv*xisq[i])}
    fplot[1]=x[mm]
    for (i in 1:n.ahead) {fplot[i+1]=xhat[mm+i]}
    ulplot[1]=x[mm]
    #for (i in 1:n.ahead) { ulplot[i+1]=fplot[i+1]+1.96*se[i]}
    for (i in 1:n.ahead) { ulplot[i+1]=fplot[i+1]-qnorm(alpha/2)*se[i]}
    llplot[1]=x[mm]
    #for (i in 1:n.ahead) { llplot[i+1]=fplot[i+1]-1.96*se[i]}
    for (i in 1:n.ahead) { llplot[i+1]=fplot[i+1]+qnorm(alpha/2)*se[i]}
    #
    if(limits==FALSE) {
      if(lastn==TRUE) {max=max(x,xhat[1:n])
      min=min(x,xhat[1:n])}
      else            {max=max(x,xhat)
      min=min(x,xhat)}}
    if(limits==TRUE) {min=min(x,llplot)
    max=max(x,ulplot)}
    #numrows <- 1
    #numcols <- 1
    timelab <- 'Time'
    valuelab <- ''
    #fig.width <- 5
    #fig.height <- 2.5
    cex.labs <- c(.8,.7,.8)
    #par(mfrow=c(numrows,numcols),mar=c(6,2,3,1))
    t<-1:n;
    np1=n+1
    np.ahead=mm+n.ahead
    tf<-mm:np.ahead
    #if (plot=='TRUE') {
      #fig.width <- 5
      #fig.height <- 2.5
      #cex.labs <- c(1.2,1.2,1.2)
      #par(mfrow=c(numrows,numcols),mar=c(9,4,3,2))
      #plot(t,x,type='o',xaxt='n',yaxt='n',cex=.8,pch=16,cex.lab=1,cex.axis=1,lwd=1,xlab='',ylab='',xlim=c(1,maxh),ylim=c(min,max),col=1)
      #axis(side=1,cex.axis=1.1,mgp=c(3,0.15,0),tcl=-.3);
      #axis(side=2,las=1,cex.axis=1.1,mgp=c(3,.4,0),tcl=-.3)
      #abline=mean(x)
      #mtext(side=c(1,2,1),cex=cex.labs,text=c(timelab,valuelab,""),line=c(1.2,2.1,1.8))
      #points(tf,fplot,type='o',lty=1,cex=.6,lwd=1,pch=1,col=2);
      #if(limits=='TRUE') {points(tf,ulplot,type='l',lty=2,cex=0.6,lwd=.75,pch=1,col=4)
        #points(tf,llplot,type='l',lty=3,cex=0.6,lwd=.75,pch=1,col=4)
     # }
    #}
    np1=n+1
    nap1=n.ahead+1
    f=fplot[2:nap1]
    # Calculate RMSE and MAD
    if(lastn==TRUE){
      t.start=n-n.ahead
      sum.rmse=0
      sum.mad=0
      for(i in 1:n.ahead) {sum.rmse=sum.rmse+(f[i]-x[t.start+i])^2
      sum.mad=sum.mad+abs(f[i]-x[t.start+i])}
      mse=sum.rmse/n.ahead
      rmse=sqrt(mse)
      mad=sum.mad/n.ahead
    }
    ll=llplot[2:nap1]
    ul=ulplot[2:nap1]
    if(lastn==TRUE){out1=list(f=f)}
    if(lastn==FALSE){out1=list(f=f)}
    return(out1)
  }

  
  numwindows = 0
  RMSEHolder = numeric()

  
if(s == 0 & d == 0)
{
  
  trainingSize = max(length(phi),length(theta)) + 1 # The plus 1 is for the backcast residuals which helps with ARMA model with q > 0
  numwindows = length(series)-(trainingSize + horizon) + 1   
  RMSEHolder = numeric(numwindows)

  # print(paste("Please Hold For a Moment, TSWGE is processing the Rolling Window RMSE with", numwindows, "windows."))
  
  for( i in 1:numwindows)
  {
    forecasts <- fore.arma.wge2(series[i:(i+(trainingSize-1))], plot = TRUE, phi = phi, theta = theta,n.ahead = horizon, xbar = mean(series))

    RMSE = sqrt(mean((series[(trainingSize+i):(trainingSize+ i + (horizon) - 1)] - forecasts$f)^2))
    
    RMSEHolder[i] = RMSE
  }
}
else
  {
    trainingSize = sum(length(phi),length(theta),s, d) + 1 # sum and plus one is to help backcast.wge, lag.max and ylim plotting issue in fore.arima.wge
    numwindows = length(series)-(trainingSize + horizon) + 1
    RMSEHolder = numeric(numwindows)

    # print(paste("Please Hold For a Moment, TSWGE is processing the Rolling Window RMSE with", numwindows, "windows."))
    
    for( i in 1:numwindows)
    {
      #invisible(capture.output(forecasts <- fore.arima.wge(series[i:(i+(trainingSize-1))],phi = phis, theta = thetas, s = s, d = d,n.ahead = horizon)))
      forecasts <- fore.aruma.wge(series[i:(i+(trainingSize-1))],phi = phi, s = s, d = d, theta = theta,n.ahead = horizon, plot=plot)
      
      RMSE = sqrt(mean((series[(trainingSize+i):(trainingSize+ i + (horizon) - 1)] - forecasts$f)^2))
      
      RMSEHolder[i] = RMSE
      
    }
  }
  
  
  RMSEHolder
  #hist(RMSEHolder, main = "RMSEs for Individual Windows")
  WindowedRMSE = mean(RMSEHolder)
  
  # print("The Summary Statistics for the Rolling Window RMSE Are:")
  # print(summary(RMSEHolder))
  # print(paste("The Rolling Window RMSE is: ",round(WindowedRMSE,3)))

#output
  invisible(list(rwRMSE = WindowedRMSE, trainingSize = trainingSize, numwindows = numwindows, horizon = horizon, s = s, d = d, phi = phi, theta = theta, RMSEs = RMSEHolder))
  
  }
```


